{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Estimation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon import nn, loss\n",
    "\n",
    "from network.rtpose_vgg import get_model\n",
    "from training.datasets.coco import get_loader\n",
    "from mxboard import SummaryWriter    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'training/dataset/COCO/images'\n",
    "mask_dir = 'training/dataset/COCO/mask'\n",
    "logdir = 'logs'\n",
    "json_path = 'training/dataset/COCO/COCO.json'\n",
    "model_path = 'model_checkpoints/'\n",
    "lr = 1.                    \n",
    "momentum = 0.9\n",
    "epochs_ft = 5\n",
    "epochs_pre = 5\n",
    "wd = 0.0                    \n",
    "nesterov = False\n",
    "optim = 'sgd'\n",
    "gpuIDs = [0]\n",
    "batch_size = 8\n",
    "print_freq = 20\n",
    "load_model = 'lr_0.1_wd_0.00001_momentum_0.8_ft_vgg_pose_1.params'\n",
    "log_key = 'notebook_tests'\n",
    "\n",
    "ctx = [mx.gpu(e) for e in gpuIDs] if gpuIDs[0] != -1 else [mx.cpu()]\n",
    "ctx = ctx[0] # single GPU for now\n",
    "\n",
    "params_transform = dict()\n",
    "params_transform['mode'] = 5\n",
    "# === aug_scale ===\n",
    "params_transform['scale_min'] = 0.5\n",
    "params_transform['scale_max'] = 1.1\n",
    "params_transform['scale_prob'] = 1\n",
    "params_transform['target_dist'] = 0.6\n",
    "# === aug_rotate ===\n",
    "params_transform['max_rotate_degree'] = 40\n",
    "\n",
    "# ===\n",
    "params_transform['center_perterb_max'] = 40\n",
    "\n",
    "# === aug_flip ===\n",
    "params_transform['flip_prob'] = 0.5\n",
    "\n",
    "params_transform['np'] = 56\n",
    "params_transform['sigma'] = 7.0\n",
    "params_transform['limb_width'] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def build_names():\n",
    "    names = []\n",
    "    for j in range(1, 7):\n",
    "        for k in range(1, 3):\n",
    "            names.append('loss_stage%d_L%d' % (j, k))\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(saved_for_loss, heat_temp, heat_weight,\n",
    "               vec_temp, vec_weight):\n",
    "\n",
    "    names = build_names()\n",
    "    saved_for_log = OrderedDict()\n",
    "    loss_fn = gluon.loss.L2Loss()\n",
    "    total_loss = 0\n",
    "\n",
    "    for j in range(6):\n",
    "        pred1 = saved_for_loss[2 * j] * vec_weight\n",
    "        gt1 = vec_temp * vec_weight\n",
    "        pred2 = saved_for_loss[2 * j + 1] * heat_weight\n",
    "        gt2 = heat_weight * heat_temp\n",
    "        # Compute losses\n",
    "        loss1 = loss_fn(pred1, gt1)\n",
    "        loss2 = loss_fn(pred2, gt2) \n",
    "        total_loss = total_loss + loss1\n",
    "        total_loss = total_loss + loss2\n",
    "        saved_for_log[names[2 * j]] = loss1.mean().asscalar()\n",
    "        saved_for_log[names[2 * j + 1]] = loss2.mean().asscalar()\n",
    "\n",
    "    saved_for_log['max_ht'] = saved_for_loss[-1][:, 0:-1, :, :].asnumpy().max()\n",
    "    saved_for_log['min_ht'] = saved_for_loss[-1][:, 0:-1, :, :].asnumpy().min()\n",
    "    saved_for_log['max_paf'] = saved_for_loss[-2].asnumpy().max()\n",
    "    saved_for_log['min_paf'] = saved_for_loss[-2].asnumpy().min()\n",
    "\n",
    "    return total_loss, saved_for_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(iterator, model, epoch, is_train=True, trainer_vgg=None, trainer_pose=None):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    \n",
    "    meter_dict = {}\n",
    "    for name in build_names():\n",
    "        meter_dict[name] = AverageMeter()\n",
    "    meter_dict['max_ht'] = AverageMeter()\n",
    "    meter_dict['min_ht'] = AverageMeter()    \n",
    "    meter_dict['max_paf'] = AverageMeter()    \n",
    "    meter_dict['min_paf'] = AverageMeter()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    for i, (img, heatmap_target, heat_mask, paf_target, paf_mask) in enumerate(iterator):\n",
    "        img = img.as_in_context(ctx)\n",
    "        heatmap_target = heatmap_target.as_in_context(ctx)\n",
    "        heat_mask = heat_mask.as_in_context(ctx)\n",
    "        paf_target = paf_target.as_in_context(ctx)\n",
    "        paf_mask = paf_mask.as_in_context(ctx)\n",
    "                \n",
    "        with autograd.record(is_train):\n",
    "            # compute output\n",
    "            _,saved_for_loss = model(img)\n",
    "\n",
    "            total_loss, saved_for_log = get_loss(saved_for_loss, heatmap_target, heat_mask,\n",
    "                   paf_target, paf_mask)\n",
    "\n",
    "            for name,_ in meter_dict.items():\n",
    "                meter_dict[name].update(saved_for_log[name], img.shape[0])\n",
    "            losses.update(total_loss.mean().asscalar(), img.shape[0])\n",
    "\n",
    "        if is_train:\n",
    "            total_loss.backward()\n",
    "            trainer_vgg.step(img.shape[0])\n",
    "            trainer_pose.step(img.shape[0])\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if i % print_freq == 0 and is_train:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'.format(epoch, i, len(iterator)))\n",
    "            print('Data time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'.format( batch_time=batch_time))\n",
    "            print('Loss {loss.val:.4f} ({loss.avg:.4f})'.format(loss=losses))\n",
    "            writer.add_scalar('data/max_ht', {log_key:meter_dict['max_ht'].avg}, i+epoch*len(iterator))\n",
    "            writer.add_scalar('data/max_paf', {log_key:meter_dict['max_paf'].avg}, i+epoch*len(iterator))\n",
    "            writer.add_scalar('data/loss', {log_key:losses.avg}, i+epoch*len(iterator)),\n",
    "            for name, value in meter_dict.items():\n",
    "                print('{name}: {loss.val:.4f} ({loss.avg:.4f})\\t'.format(name=name, loss=value))\n",
    "            writer.flush()\n",
    "    return losses.avg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "train dataset len: 121522\n",
      "val dataset len: 4873\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "# load data\n",
    "train_data = get_loader(json_path, data_dir,\n",
    "                        mask_dir, 368, 8,\n",
    "                        'vgg', batch_size, params_transform = params_transform, \n",
    "                        shuffle=True, training=True, num_workers=8)\n",
    "print('train dataset len: {}'.format(len(train_data._dataset)))\n",
    "\n",
    "# validation data\n",
    "valid_data = get_loader(json_path, data_dir, mask_dir, 368,\n",
    "                            8, preprocess='vgg', training=False,\n",
    "                            batch_size=batch_size, params_transform = params_transform, shuffle=False, num_workers=8)\n",
    "print('val dataset len: {}'.format(len(valid_data._dataset)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(trunk='vgg19')\n",
    "model.collect_params().reset_ctx(ctx)\n",
    "if load_model != '':\n",
    "    model.load_parameters(os.path.join(model_path, load_model), ctx=ctx)\n",
    "model.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training first with backbone fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the VGG pre-trained weights for now\n",
    "trainer_vgg = gluon.Trainer(model.model0.collect_params('.*CPM.*'), 'sgd', {'learning_rate':lr, 'momentum': momentum, 'wd':wd})\n",
    "trainer_pose = gluon.Trainer(model.collect_params('block.*'), 'sgd', {'learning_rate':lr, 'momentum': momentum, 'wd':wd}) \n",
    "                                                                                          \n",
    "writer = SummaryWriter(logdir=logdir)       \n",
    "for epoch in range(epochs_pre):\n",
    "    # train for one epoch\n",
    "    train_loss = run_epoch(train_data, model, epoch, is_train=True, trainer_vgg=trainer_vgg, trainer_pose=trainer_pose)\n",
    "    model.save_parameters(os.path.join(model_path, log_key+'_vgg_pose_'+str(epoch)+'.params'))\n",
    "    # evaluate on validation set\n",
    "    val_loss = run_epoch(valid_data, model, epoch, is_train=False)  \n",
    "                  \n",
    "    writer.add_scalar('epoch/train_loss', {log_key: train_loss}, epoch)\n",
    "    writer.add_scalar('epoch/val_loss', {log_key: val_loss}, epoch)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optim == 'sgd':\n",
    "    trainer_vgg = gluon.Trainer(model.model0.collect_params(), 'sgd', {'learning_rate':lr, 'momentum': momentum, 'wd':wd})\n",
    "    trainer_pose = gluon.Trainer(model.collect_params('block.*'), 'sgd', {'learning_rate':lr, 'momentum': momentum, 'wd':wd}) \n",
    "elif optim == 'adam':\n",
    "    trainer_vgg = gluon.Trainer(model.model0.collect_params(), 'adam', {'learning_rate':lr, 'wd':wd})\n",
    "    trainer_pose = gluon.Trainer(model.collect_params('block.*'), 'adam', {'learning_rate':lr, 'wd':wd}) \n",
    "else:\n",
    "    raise \"Unknown optim \" + optim\n",
    "log_key += '_ft'        \n",
    "\n",
    "for epoch in range(epochs_pre, epochs_pre+epochs_ft):\n",
    "    # train for one epoch\n",
    "    train_loss = run_epoch(train_data, model, epoch, is_train=True, trainer_vgg=trainer_vgg, trainer_pose=trainer_pose)\n",
    "    model.save_parameters(os.path.join(model_path, log_key+'_vgg_pose_'+str(epoch)+'.params'))\n",
    "    # evaluate on validation set\n",
    "    val_loss = run_epoch(valid_data, model, epoch, is_train=False)  \n",
    "                                 \n",
    "    writer.add_scalar('epoch_ft/train_loss', {log_key: train_loss}, epoch)\n",
    "    writer.add_scalar('epoch_ft/val_loss', {log_key: val_loss}, epoch)                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
